Real-Time Hand Gesture Recognition Using Machine Learning

Project Description:

This project implements a real-time hand gesture recognition system that uses computer vision and machine learning to detect and classify hand gestures through a webcam feed. The system leverages MediaPipe for hand landmark extraction and a trained machine learning model for gesture classification. It demonstrates key steps in an applied computer vision pipeline, including landmark feature extraction, model integration, real-time inference, and visualization of predictions. The project provides practical exposure to building interactive AI systems for humanâ€“computer interaction.

Key Highlights:

* Real-time webcam video capture using OpenCV
* Hand landmark detection with MediaPipe
* Feature extraction from 3D hand landmark coordinates
* Gesture classification using trained ML model
* On-screen prediction display
* Recognition of predefined gestures (Palm, Fist, Thumbs Up, Peace)

Technologies & Libraries:

* Python
* OpenCV
* MediaPipe
* NumPy
* Scikit-learn (for model training)
* Pickle (model loading)

Workflow Overview:

1. Import required libraries
2. Load trained gesture classification model
3. Initialize MediaPipe hand detection module
4. Capture video stream from webcam
5. Detect hand landmarks in each frame
6. Extract landmark features for prediction
7. Classify gesture using trained model
8. Display gesture label on live video feed

Learning Outcomes:

* Understanding real-time computer vision pipelines
* Applying landmark-based feature extraction
* Integrating trained ML models into live applications
* Working with video streams and visual overlays
* Building interactive AI-driven user interfaces
